F tests/notebooks_test.py::TestNotebooks::test_data_pipeline_tutorial
 self = <tests.notebooks_test.TestNotebooks testMethod=test_data_pipeline_tutorial>
 
     def test_data_pipeline_tutorial(self):
 >       assert self.execute_notebook("tutorials/notebooks/data_pipeline.ipynb")
 
 tests/notebooks_test.py:14: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
 notebook_path = 'tutorials/notebooks/data_pipeline.ipynb'
 
     @staticmethod
     def execute_notebook(notebook_path: str):
 >       with open(notebook_path, encoding='utf-8') as notebook:
 E       FileNotFoundError: [Errno 2] No such file or directory: 'tutorials/notebooks/data_pipeline.ipynb'
 
 tests/notebooks_test.py:21: FileNotFoundError
F tests/notebooks_test.py::TestNotebooks::test_embedding_tokens_tutorial
 self = <tests.notebooks_test.TestNotebooks testMethod=test_embedding_tokens_tutorial>
 
     def test_embedding_tokens_tutorial(self):
 >       assert self.execute_notebook("tutorials/notebooks/embedding_tokens.ipynb")
 
 tests/notebooks_test.py:17: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
 notebook_path = 'tutorials/notebooks/embedding_tokens.ipynb'
 
     @staticmethod
     def execute_notebook(notebook_path: str):
 >       with open(notebook_path, encoding='utf-8') as notebook:
 E       FileNotFoundError: [Errno 2] No such file or directory: 'tutorials/notebooks/embedding_tokens.ipynb'
 
 tests/notebooks_test.py:21: FileNotFoundError
F tests/notebooks_test.py::TestNotebooks::test_vocabulary_tutorial
 self = <tests.notebooks_test.TestNotebooks testMethod=test_vocabulary_tutorial>
 
     def test_vocabulary_tutorial(self):
 >       assert self.execute_notebook("tutorials/notebooks/vocabulary.ipynb")
 
 tests/notebooks_test.py:11: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
 notebook_path = 'tutorials/notebooks/vocabulary.ipynb'
 
     @staticmethod
     def execute_notebook(notebook_path: str):
 >       with open(notebook_path, encoding='utf-8') as notebook:
 E       FileNotFoundError: [Errno 2] No such file or directory: 'tutorials/notebooks/vocabulary.ipynb'
 
 tests/notebooks_test.py:21: FileNotFoundError
F tests/commands/evaluate_test.py::TestEvaluate::test_evaluate_from_args
 self = <tests.commands.evaluate_test.TestEvaluate testMethod=test_evaluate_from_args>
 
     @flaky
     def test_evaluate_from_args(self):
         parser = argparse.ArgumentParser(description="Testing")
         subparsers = parser.add_subparsers(title='Commands', metavar='')
         Evaluate().add_subparser('evaluate', subparsers)
     
         snake_args = ["evaluate",
                       "--archive_file", "tests/fixtures/bidaf/serialization/model.tar.gz",
                       "--evaluation_data_file", "tests/fixtures/data/squad.json",
                       "--cuda_device", "-1"]
     
         kebab_args = ["evaluate",
                       "--archive-file", "tests/fixtures/bidaf/serialization/model.tar.gz",
                       "--evaluation-data-file", "tests/fixtures/data/squad.json",
                       "--cuda-device", "-1"]
     
         for raw_args in [snake_args, kebab_args]:
             args = parser.parse_args(raw_args)
 >           metrics = evaluate_from_args(args)
 
 tests/commands/evaluate_test.py:30: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 allennlp/commands/evaluate.py:244: in evaluate_from_args
     serialization_directory)
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
 model = BidirectionalAttentionFlow(
   (_text_field_embedder): BasicTextFieldEmbedder(
     (token_embedder_tokens): Embedding(
 ...d_predictor): TimeDistributed(
     (_module): Linear(in_features=50, out_features=1)
   )
   (_dropout): Dropout(p=0.2)
 )
 dataset = <allennlp.data.dataset.Dataset object at 0x128df4748>, iterator = <allennlp.data.iterators.basic_iterator.BasicIterator object at 0x128dfa160>, cuda_device = -1
 serialization_directory = 'tests/fixtures/bidaf/serialization'
 
     def evaluate(model: Model,
                  dataset: Dataset,
                  iterator: BasicIterator,
                  cuda_device: int,
                  serialization_directory: str) -> Dict[str, Any]:
         model.eval()
     
         generator = iterator(dataset,
                              num_epochs=1,
                              cuda_device=cuda_device,
                              shuffle=False,
                              for_training=False)
         logger.info("Iterating over dataset")
         generator_tqdm = tqdm.tqdm(generator, total=iterator.get_num_batches(dataset))
     
     
         for batch in generator_tqdm:
             model(**batch)
             metrics = model.get_metrics()
             description = ', '.join(["%s: %.5f" % (name, value)
                                      for name, value in metrics.items() if "overall" in name]) + " ||"
             generator_tqdm.set_description(description)
     
         metrics = model.get_metrics()
 >       golds = metrics["gold_spans"]
 E       KeyError: 'gold_spans'
 
 allennlp/commands/evaluate.py:102: KeyError
. tests/commands/main_test.py::TestMain::test_fails_on_unknown_command
. tests/commands/main_test.py::TestMain::test_subcommand_overrides
F tests/commands/main_test.py::TestMain::test_warn_on_deprecated_flags
 self = <tests.commands.main_test.TestMain testMethod=test_warn_on_deprecated_flags>
 
     def test_warn_on_deprecated_flags(self):
         sys.argv = ["[executable]",
                     "evaluate",
                     "--archive_file", "tests/fixtures/bidaf/serialization/model.tar.gz",
                     "--evaluation_data_file", "tests/fixtures/data/squad.json",
                     "--cuda_device", "-1"]
     
     
         with self.assertLogs(level=logging.WARNING) as context:
 >           main()
 
 tests/commands/main_test.py:31: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 allennlp/commands/__init__.py:81: in main
     args.func(args)
 allennlp/commands/evaluate.py:244: in evaluate_from_args
     serialization_directory)
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
 model = BidirectionalAttentionFlow(
   (_text_field_embedder): BasicTextFieldEmbedder(
     (token_embedder_tokens): Embedding(
 ...d_predictor): TimeDistributed(
     (_module): Linear(in_features=50, out_features=1)
   )
   (_dropout): Dropout(p=0.2)
 )
 dataset = <allennlp.data.dataset.Dataset object at 0x125079208>, iterator = <allennlp.data.iterators.basic_iterator.BasicIterator object at 0x128e2cda0>, cuda_device = -1
 serialization_directory = 'tests/fixtures/bidaf/serialization'
 
     def evaluate(model: Model,
                  dataset: Dataset,
                  iterator: BasicIterator,
                  cuda_device: int,
                  serialization_directory: str) -> Dict[str, Any]:
         model.eval()
     
         generator = iterator(dataset,
                              num_epochs=1,
                              cuda_device=cuda_device,
                              shuffle=False,
                              for_training=False)
         logger.info("Iterating over dataset")
         generator_tqdm = tqdm.tqdm(generator, total=iterator.get_num_batches(dataset))
     
     
         for batch in generator_tqdm:
             model(**batch)
             metrics = model.get_metrics()
             description = ', '.join(["%s: %.5f" % (name, value)
                                      for name, value in metrics.items() if "overall" in name]) + " ||"
             generator_tqdm.set_description(description)
     
         metrics = model.get_metrics()
 >       golds = metrics["gold_spans"]
 E       KeyError: 'gold_spans'
 
 allennlp/commands/evaluate.py:102: KeyError
. tests/commands/predict_test.py::TestPredict::test_add_predict_subparser
. tests/commands/predict_test.py::TestPredict::test_batch_prediction_works_with_known_model
. tests/commands/predict_test.py::TestPredict::test_can_override_predictors
. tests/commands/predict_test.py::TestPredict::test_fails_without_required_args
. tests/commands/predict_test.py::TestPredict::test_works_with_known_model
. tests/commands/serve_test.py::TestServe::test_add_serve
. tests/commands/train_test.py::TestTrain::test_train_args
. tests/commands/train_test.py::TestTrain::test_train_model
F tests/commands/train_test.py::TestTrain::test_train_with_test_set
 self = <tests.commands.train_test.TestTrain testMethod=test_train_with_test_set>
 
     def test_train_with_test_set(self):
         params = Params({
                 "model": {
                         "type": "simple_tagger",
                         "text_field_embedder": {
                                 "tokens": {
                                         "type": "embedding",
                                         "embedding_dim": 5
                                 }
                         },
                         "stacked_encoder": {
                                 "type": "lstm",
                                 "input_size": 5,
                                 "hidden_size": 7,
                                 "num_layers": 2
                         }
                 },
                 "dataset_reader": {"type": "sequence_tagging"},
                 "train_data_path": 'tests/fixtures/data/sequence_tagging.tsv',
                 "test_data_path": 'tests/fixtures/data/sequence_tagging.tsv',
                 "validation_data_path": 'tests/fixtures/data/sequence_tagging.tsv',
                 "evaluate_on_test": True,
                 "iterator": {"type": "basic", "batch_size": 2},
                 "trainer": {
                         "num_epochs": 2,
                         "optimizer": "adam"
                 }
         })
     
 >       train_model(params, serialization_dir=self.TEST_DIR)
 
 tests/commands/train_test.py:68: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
 params = <allennlp.common.params.Params object at 0x128f3d6d8>, serialization_dir = '/tmp/allennlp_tests/'
 
     def train_model(params: Params, serialization_dir: str) -> Model:
         """
         This function can be used as an entry point to running models in AllenNLP
         directly from a JSON specification using a :class:`Driver`. Note that if
         you care about reproducibility, you should avoid running code using Pytorch
         or numpy which affect the reproducibility of your experiment before you
         import and use this function, these libraries rely on random seeds which
         can be set in this function via a JSON specification file. Note that this
         function performs training and will also evaluate the trained model on
         development and test sets if provided in the parameter json.
     
         Parameters
         ----------
         params: Params, required.
             A parameter object specifying an AllenNLP Experiment.
         serialization_dir: str, required
             The directory in which to save results and logs.
         """
         prepare_environment(params)
     
         os.makedirs(serialization_dir, exist_ok=True)
         sys.stdout = TeeLogger(os.path.join(serialization_dir, "stdout.log"), sys.stdout)  # type: ignore
         sys.stderr = TeeLogger(os.path.join(serialization_dir, "stderr.log"), sys.stderr)  # type: ignore
         handler = logging.FileHandler(os.path.join(serialization_dir, "python_logging.log"))
         handler.setLevel(logging.INFO)
         handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(message)s'))
         logging.getLogger().addHandler(handler)
         serialization_params = deepcopy(params).as_dict(quiet=True)
         with open(os.path.join(serialization_dir, "model_params.json"), "w") as param_file:
             json.dump(serialization_params, param_file, indent=4)
     
         # Now we begin assembling the required parts for the Trainer.
         dataset_reader = DatasetReader.from_params(params.pop('dataset_reader'))
     
         train_data_path = params.pop('train_data_path')
         logger.info("Reading training data from %s", train_data_path)
         train_data = dataset_reader.read(train_data_path)
     
         all_datasets: Dict[str, Dataset] = {"train": train_data}
     
         validation_data_path = params.pop('validation_data_path', None)
         if validation_data_path is not None:
             logger.info("Reading validation data from %s", validation_data_path)
             validation_data = dataset_reader.read(validation_data_path)
             all_datasets["validation"] = validation_data
         else:
             validation_data = None
     
         test_data_path = params.pop("test_data_path", None)
         if test_data_path is not None:
             logger.info("Reading test data from %s", test_data_path)
             test_data = dataset_reader.read(test_data_path)
             all_datasets["test"] = test_data
         else:
             test_data = None
     
         datasets_for_vocab_creation = set(params.pop("datasets_for_vocab_creation", all_datasets))
     
         for dataset in datasets_for_vocab_creation:
             if dataset not in all_datasets:
                 raise ConfigurationError(f"invalid 'dataset_for_vocab_creation' {dataset}")
     
         logger.info("Creating a vocabulary using %s data.", ", ".join(datasets_for_vocab_creation))
         vocab = Vocabulary.from_params(params.pop("vocabulary", {}),
                                        Dataset([instance for key, dataset in all_datasets.items()
                                                 for instance in dataset.instances
                                                 if key in datasets_for_vocab_creation]))
         vocab.save_to_files(os.path.join(serialization_dir, "vocabulary"))
     
         model = Model.from_params(vocab, params.pop('model'))
         iterator = DataIterator.from_params(params.pop("iterator"))
     
         train_data.index_instances(vocab)
         if validation_data:
             validation_data.index_instances(vocab)
     
         trainer_params = params.pop("trainer")
         trainer = Trainer.from_params(model,
                                       serialization_dir,
                                       iterator,
                                       train_data,
                                       validation_data,
                                       trainer_params,
                                       params.files_to_archive)
     
         evaluate_on_test = params.pop("evaluate_on_test", False)
         params.assert_empty('base train command')
         trainer.train()
     
         # Now tar up results
         archive_model(serialization_dir, files_to_archive=params.files_to_archive)
     
         if test_data and evaluate_on_test:
             test_data.index_instances(vocab)
 >           evaluate(model, test_data, iterator, cuda_device=trainer._cuda_device)  # pylint: disable=protected-access
 E           TypeError: evaluate() missing 1 required positional argument: 'serialization_directory'
 
 allennlp/commands/train.py:186: TypeError
. tests/common/file_utils_test.py::TestFileUtils::test_cached_path
. tests/common/file_utils_test.py::TestFileUtils::test_get_from_cache
. tests/common/file_utils_test.py::TestFileUtils::test_url_to_filename
. tests/common/file_utils_test.py::TestFileUtils::test_url_to_filename_with_etags
. tests/common/file_utils_test.py::TestFileUtils::test_url_to_filename_with_etags_eliminates_quotes
. tests/common/params_test.py::TestParams::test_add_file_to_archive
. tests/common/params_test.py::TestParams::test_load_from_file
. tests/common/params_test.py::TestParams::test_overrides
. tests/common/registrable_test.py::TestRegistrable::test_registrable_functionality_works
. tests/common/registrable_test.py::TestRegistrable::test_registry_has_builtin_dataset_readers
. tests/common/registrable_test.py::TestRegistrable::test_registry_has_builtin_initializers
. tests/common/registrable_test.py::TestRegistrable::test_registry_has_builtin_iterators
. tests/common/registrable_test.py::TestRegistrable::test_registry_has_builtin_learning_rate_schedulers
. tests/common/registrable_test.py::TestRegistrable::test_registry_has_builtin_regularizers
. tests/common/registrable_test.py::TestRegistrable::test_registry_has_builtin_seq2seq_encoders
. tests/common/registrable_test.py::TestRegistrable::test_registry_has_builtin_seq2vec_encoders
. tests/common/registrable_test.py::TestRegistrable::test_registry_has_builtin_similarity_functions
. tests/common/registrable_test.py::TestRegistrable::test_registry_has_builtin_text_field_embedders
. tests/common/registrable_test.py::TestRegistrable::test_registry_has_builtin_token_embedders
. tests/common/registrable_test.py::TestRegistrable::test_registry_has_builtin_token_indexers
. tests/common/registrable_test.py::TestRegistrable::test_registry_has_builtin_tokenizers
. tests/common/test_util.py::TestCommonUtils::test_group_by_count
. tests/common/test_util.py::TestCommonUtils::test_namespace_match
. tests/common/test_util.py::TestCommonUtils::test_pad_sequence_to_length
. tests/common/test_util.py::TestCommonUtils::test_sanitize
s tests/custom_extensions/alternating_highway_lstm_test.py::TestCustomHighwayLSTM::test_large_model
 Skipped: No CUDA device registered.
s tests/custom_extensions/alternating_highway_lstm_test.py::TestCustomHighwayLSTM::test_small_model
 Skipped: No CUDA device registered.
s tests/custom_extensions/alternating_highway_lstm_test.py::TestCustomHighwayLSTM::test_validation_forward_pass_is_deterministic_in_model_with_dropout
 Skipped: No CUDA device registered.
. tests/data/dataset_test.py::TestDataset::test_as_tensor_dict
. tests/data/dataset_test.py::TestDataset::test_instances_must_have_homogeneous_fields
. tests/data/dataset_test.py::TestDataset::test_padding_lengths_uses_max_instance_lengths
. tests/data/vocabulary_test.py::TestVocabulary::test_add_word_to_index_gives_consistent_results
. tests/data/vocabulary_test.py::TestVocabulary::test_from_dataset_respects_exclusive_embedding_file
. tests/data/vocabulary_test.py::TestVocabulary::test_from_dataset_respects_inclusive_embedding_file
. tests/data/vocabulary_test.py::TestVocabulary::test_from_dataset_respects_min_count
. tests/data/vocabulary_test.py::TestVocabulary::test_from_params
. tests/data/vocabulary_test.py::TestVocabulary::test_namespace_dependent_default_dict
. tests/data/vocabulary_test.py::TestVocabulary::test_namespaces
. tests/data/vocabulary_test.py::TestVocabulary::test_saving_and_loading
. tests/data/vocabulary_test.py::TestVocabulary::test_saving_and_loading_works_with_byte_encoding
. tests/data/vocabulary_test.py::TestVocabulary::test_set_from_file_reads_non_padded_files
. tests/data/vocabulary_test.py::TestVocabulary::test_set_from_file_reads_padded_files
. tests/data/vocabulary_test.py::TestVocabulary::test_unknown_token
. tests/data/dataset_readers/coref_reader_test.py::TestCorefReader::test_read_from_file
. tests/data/dataset_readers/language_modeling_dataset_test.py::TestLanguageModelingDatasetReader::test_read_from_file
. tests/data/dataset_readers/ontonotes_test.py::TestOntonotes::test_dataset_iterator
. tests/data/dataset_readers/ontonotes_test.py::TestOntonotes::test_dataset_path_iterator
. tests/data/dataset_readers/seq2seq_test.py::TestSeq2SeqDatasetReader::test_default_format
. tests/data/dataset_readers/seq2seq_test.py::TestSeq2SeqDatasetReader::test_source_add_start_token
. tests/data/dataset_readers/sequence_tagging_test.py::TestSequenceTaggingDatasetReader::test_brown_corpus_format
. tests/data/dataset_readers/sequence_tagging_test.py::TestSequenceTaggingDatasetReader::test_default_format
. tests/data/dataset_readers/snli_reader_test.py::TestSnliReader::test_read_from_file
. tests/data/dataset_readers/srl_dataset_reader_test.py::TestSrlReader::test_read_from_file
F tests/data/dataset_readers/framenet/full_text_reader_test.py::TestFullTextReader::test_fill_missing_spans
 self = <full_text_reader_test.TestFullTextReader testMethod=test_fill_missing_spans>
 
     def test_fill_missing_spans(self):
         sentence_length = 15
         fes = [(3, 3, "a"), (6, 10, "b"), (12, 12, "c")]
         reader = FrameNetFullTextReader(max_span_width=10,
 >                                       data_path="data/fndata-1.5/")
 
 tests/data/dataset_readers/framenet/full_text_reader_test.py:163: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 allennlp/data/dataset_readers/framenet/full_text_reader.py:130: in __init__
     self._ontology = FrameOntology(data_path)
 allennlp/data/dataset_readers/framenet/ontology_reader.py:31: in __init__
     self._read(data_path)
 allennlp/data/dataset_readers/framenet/ontology_reader.py:70: in _read
     self._read_ontology(frame_index_path)
 allennlp/data/dataset_readers/framenet/ontology_reader.py:60: in _read_ontology
     with codecs.open(frame_index_filename, "rb", "utf-8") as frame_file:
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
 filename = 'data/fndata-1.5/frameIndex.xml', mode = 'rb', encoding = 'utf-8', errors = 'strict', buffering = 1
 
     def open(filename, mode='r', encoding=None, errors='strict', buffering=1):
     
         """ Open an encoded file using the given mode and return
             a wrapped version providing transparent encoding/decoding.
     
             Note: The wrapped version will only accept the object format
             defined by the codecs, i.e. Unicode objects for most builtin
             codecs. Output is also codec dependent and will usually be
             Unicode as well.
     
             Underlying encoded files are always opened in binary mode.
             The default file mode is 'r', meaning to open the file in read mode.
     
             encoding specifies the encoding which is to be used for the
             file.
     
             errors may be given to define the error handling. It defaults
             to 'strict' which causes ValueErrors to be raised in case an
             encoding error occurs.
     
             buffering has the same meaning as for the builtin open() API.
             It defaults to line buffered.
     
             The returned wrapped file object provides an extra attribute
             .encoding which allows querying the used encoding. This
             attribute is only available if an encoding was specified as
             parameter.
     
         """
         if encoding is not None and \
            'b' not in mode:
             # Force opening of the file in binary mode
             mode = mode + 'b'
 >       file = builtins.open(filename, mode, buffering)
 E       FileNotFoundError: [Errno 2] No such file or directory: 'data/fndata-1.5/frameIndex.xml'
 
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/codecs.py:897: FileNotFoundError
F tests/data/dataset_readers/framenet/full_text_reader_test.py::TestFullTextReader::test_read_from_file
 self = <full_text_reader_test.TestFullTextReader testMethod=test_read_from_file>
 
     def test_read_from_file(self):
         max_span_width = 10
         reader = FrameNetFullTextReader(max_span_width=max_span_width,
 >                                       data_path="data/fndata-1.5/")
 
 tests/data/dataset_readers/framenet/full_text_reader_test.py:13: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 allennlp/data/dataset_readers/framenet/full_text_reader.py:130: in __init__
     self._ontology = FrameOntology(data_path)
 allennlp/data/dataset_readers/framenet/ontology_reader.py:31: in __init__
     self._read(data_path)
 allennlp/data/dataset_readers/framenet/ontology_reader.py:70: in _read
     self._read_ontology(frame_index_path)
 allennlp/data/dataset_readers/framenet/ontology_reader.py:60: in _read_ontology
     with codecs.open(frame_index_filename, "rb", "utf-8") as frame_file:
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
 filename = 'data/fndata-1.5/frameIndex.xml', mode = 'rb', encoding = 'utf-8', errors = 'strict', buffering = 1
 
     def open(filename, mode='r', encoding=None, errors='strict', buffering=1):
     
         """ Open an encoded file using the given mode and return
             a wrapped version providing transparent encoding/decoding.
     
             Note: The wrapped version will only accept the object format
             defined by the codecs, i.e. Unicode objects for most builtin
             codecs. Output is also codec dependent and will usually be
             Unicode as well.
     
             Underlying encoded files are always opened in binary mode.
             The default file mode is 'r', meaning to open the file in read mode.
     
             encoding specifies the encoding which is to be used for the
             file.
     
             errors may be given to define the error handling. It defaults
             to 'strict' which causes ValueErrors to be raised in case an
             encoding error occurs.
     
             buffering has the same meaning as for the builtin open() API.
             It defaults to line buffered.
     
             The returned wrapped file object provides an extra attribute
             .encoding which allows querying the used encoding. This
             attribute is only available if an encoding was specified as
             parameter.
     
         """
         if encoding is not None and \
            'b' not in mode:
             # Force opening of the file in binary mode
             mode = mode + 'b'
 >       file = builtins.open(filename, mode, buffering)
 E       FileNotFoundError: [Errno 2] No such file or directory: 'data/fndata-1.5/frameIndex.xml'
 
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/codecs.py:897: FileNotFoundError
. tests/data/dataset_readers/ontonotes/crf_srl_reader_test.py::TestCrfSrlReader::test_read_from_file
. tests/data/dataset_readers/ontonotes/span_annotation_reader_test.py::TestSpanAnnotationReader::test_read_from_file
. tests/data/dataset_readers/ontonotes/syntactic_constituent_reader_test.py::TestSyntacticConstitReader::test_read_from_file
. tests/data/dataset_readers/reading_comprehension/squad_test.py::TestSquadReader::test_can_build_from_params
. tests/data/dataset_readers/reading_comprehension/squad_test.py::TestSquadReader::test_read_from_file
. tests/data/dataset_readers/reading_comprehension/triviaqa_test.py::TestTriviaQaReader::test_read
. tests/data/dataset_readers/reading_comprehension/util_test.py::TestReadingComprehensionUtil::test_char_span_to_token_span_handles_easy_cases
. tests/data/dataset_readers/reading_comprehension/util_test.py::TestReadingComprehensionUtil::test_char_span_to_token_span_handles_hard_cases
. tests/data/fields/array_field_test.py::TestArrayField::test_as_tensor_handles_larger_padding_dimensions
. tests/data/fields/array_field_test.py::TestArrayField::test_get_padding_lengths_correctly_returns_ordered_shape
. tests/data/fields/array_field_test.py::TestArrayField::test_padding_handles_list_fields
. tests/data/fields/index_field_test.py::TestIndexField::test_as_tensor_converts_field_correctly
. tests/data/fields/index_field_test.py::TestIndexField::test_index_field_empty_field_works
. tests/data/fields/index_field_test.py::TestIndexField::test_index_field_inherits_padding_lengths_from_text_field
. tests/data/fields/index_field_test.py::TestIndexField::test_index_field_raises_on_incorrect_label_type
. tests/data/fields/label_field_test.py::TestLabelField::test_as_tensor_returns_integer_tensor
. tests/data/fields/label_field_test.py::TestLabelField::test_class_variables_for_namespace_warnings_work_correctly
. tests/data/fields/label_field_test.py::TestLabelField::test_label_field_can_index_with_vocab
. tests/data/fields/label_field_test.py::TestLabelField::test_label_field_empty_field_works
. tests/data/fields/label_field_test.py::TestLabelField::test_label_field_raises_with_incorrect_label_type
. tests/data/fields/label_field_test.py::TestLabelField::test_label_field_raises_with_non_integer_labels_and_no_indexing
. tests/data/fields/list_field_test.py::TestListField::test_all_fields_padded_to_max_length
. tests/data/fields/list_field_test.py::TestListField::test_as_tensor_can_handle_multiple_token_indexers
. tests/data/fields/list_field_test.py::TestListField::test_as_tensor_can_handle_multiple_token_indexers_and_empty_fields
. tests/data/fields/list_field_test.py::TestListField::test_fields_can_pad_to_greater_than_max_length
. tests/data/fields/list_field_test.py::TestListField::test_get_padding_lengths
. tests/data/fields/list_field_test.py::TestListField::test_list_field_can_handle_empty_index_fields
. tests/data/fields/list_field_test.py::TestListField::test_list_field_can_handle_empty_sequence_label_fields
. tests/data/fields/list_field_test.py::TestListField::test_list_field_can_handle_empty_text_fields
. tests/data/fields/list_field_test.py::TestListField::test_nested_list_fields_are_padded_correctly
. tests/data/fields/sequence_label_field_test.py::TestSequenceLabelField::test_as_tensor_produces_integer_targets
. tests/data/fields/sequence_label_field_test.py::TestSequenceLabelField::test_class_variables_for_namespace_warnings_work_correctly
. tests/data/fields/sequence_label_field_test.py::TestSequenceLabelField::test_count_vocab_items_correctly_indexes_tags
. tests/data/fields/sequence_label_field_test.py::TestSequenceLabelField::test_index_converts_field_correctly
. tests/data/fields/sequence_label_field_test.py::TestSequenceLabelField::test_sequence_label_field_raises_on_incorrect_type
. tests/data/fields/sequence_label_field_test.py::TestSequenceLabelField::test_tag_length_mismatch_raises
. tests/data/fields/text_field_test.py::TestTextField::test_as_tensor_handles_characters
. tests/data/fields/text_field_test.py::TestTextField::test_as_tensor_handles_longer_lengths
. tests/data/fields/text_field_test.py::TestTextField::test_as_tensor_handles_words
. tests/data/fields/text_field_test.py::TestTextField::test_as_tensor_handles_words_and_characters_with_longer_lengths
. tests/data/fields/text_field_test.py::TestTextField::test_field_counts_vocab_items_correctly
. tests/data/fields/text_field_test.py::TestTextField::test_get_padding_lengths_raises_if_no_indexed_tokens
. tests/data/fields/text_field_test.py::TestTextField::test_index_converts_field_correctly
. tests/data/fields/text_field_test.py::TestTextField::test_padding_lengths_are_computed_correctly
. tests/data/iterators/adaptive_iterator_test.py::TestAdaptiveIterator::test_biggest_batch_first_passes_off_to_bucket_iterator
. tests/data/iterators/adaptive_iterator_test.py::TestAdaptiveIterator::test_create_batches_groups_correctly
. tests/data/iterators/adaptive_iterator_test.py::TestAdaptiveIterator::test_create_batches_respects_maximum_batch_size
. tests/data/iterators/adaptive_iterator_test.py::TestAdaptiveIterator::test_from_params
. tests/data/iterators/basic_iterator_test.py::TestBasicIterator::test_call_iterates_over_data_forever
. tests/data/iterators/basic_iterator_test.py::TestBasicIterator::test_create_batches_groups_correctly
. tests/data/iterators/basic_iterator_test.py::TestBasicIterator::test_from_params
. tests/data/iterators/basic_iterator_test.py::TestBasicIterator::test_yield_one_epoch_iterates_over_the_data_once
. tests/data/iterators/bucket_iterator_test.py::TestBucketIterator::test_biggest_batch_first_works
. tests/data/iterators/bucket_iterator_test.py::TestBucketIterator::test_create_batches_groups_correctly
. tests/data/iterators/bucket_iterator_test.py::TestBucketIterator::test_from_params
. tests/data/token_indexers/character_token_indexer_test.py::CharacterTokenIndexerTest::test_as_array_produces_token_sequence
. tests/data/token_indexers/character_token_indexer_test.py::CharacterTokenIndexerTest::test_count_vocab_items_respects_casing
. tests/data/token_indexers/character_token_indexer_test.py::CharacterTokenIndexerTest::test_token_to_indices_produces_correct_characters
. tests/data/token_indexers/dep_label_indexer_test.py::TestDepLabelIndexer::test_as_array_produces_token_sequence
. tests/data/token_indexers/dep_label_indexer_test.py::TestDepLabelIndexer::test_count_vocab_items_uses_pos_tags
. tests/data/token_indexers/dep_label_indexer_test.py::TestDepLabelIndexer::test_padding_functions
. tests/data/token_indexers/dep_label_indexer_test.py::TestDepLabelIndexer::test_token_to_indices_uses_pos_tags
. tests/data/token_indexers/elmo_indexer_test.py::TestELMoTokenCharactersIndexer::test_bos_to_char_ids
. tests/data/token_indexers/elmo_indexer_test.py::TestELMoTokenCharactersIndexer::test_elmo_as_array_produces_token_sequence
. tests/data/token_indexers/elmo_indexer_test.py::TestELMoTokenCharactersIndexer::test_eos_to_char_ids
. tests/data/token_indexers/elmo_indexer_test.py::TestELMoTokenCharactersIndexer::test_unicode_to_char_ids
. tests/data/token_indexers/ner_tag_indexer_test.py::TestNerTagIndexer::test_as_array_produces_token_sequence
. tests/data/token_indexers/ner_tag_indexer_test.py::TestNerTagIndexer::test_count_vocab_items_uses_ner_tags
. tests/data/token_indexers/ner_tag_indexer_test.py::TestNerTagIndexer::test_padding_functions
. tests/data/token_indexers/ner_tag_indexer_test.py::TestNerTagIndexer::test_token_to_indices_uses_ner_tags
. tests/data/token_indexers/pos_tag_indexer_test.py::TestPosTagIndexer::test_as_array_produces_token_sequence
. tests/data/token_indexers/pos_tag_indexer_test.py::TestPosTagIndexer::test_count_vocab_items_uses_pos_tags
. tests/data/token_indexers/pos_tag_indexer_test.py::TestPosTagIndexer::test_padding_functions
. tests/data/token_indexers/pos_tag_indexer_test.py::TestPosTagIndexer::test_token_to_indices_uses_pos_tags
. tests/data/token_indexers/single_id_token_indexer_test.py::TestSingleIdTokenIndexer::test_as_array_produces_token_sequence
. tests/data/token_indexers/single_id_token_indexer_test.py::TestSingleIdTokenIndexer::test_count_vocab_items_respects_casing
. tests/data/tokenizers/character_tokenizer_test.py::TestCharacterTokenizer::test_handles_byte_encoding
. tests/data/tokenizers/character_tokenizer_test.py::TestCharacterTokenizer::test_splits_into_characters
. tests/data/tokenizers/word_splitter_test.py::TestSimpleWordSplitter::test_tokenize_handles_complex_punctuation
. tests/data/tokenizers/word_splitter_test.py::TestSimpleWordSplitter::test_tokenize_handles_contraction
. tests/data/tokenizers/word_splitter_test.py::TestSimpleWordSplitter::test_tokenize_handles_final_apostrophe
. tests/data/tokenizers/word_splitter_test.py::TestSimpleWordSplitter::test_tokenize_handles_multiple_contraction
. tests/data/tokenizers/word_splitter_test.py::TestSimpleWordSplitter::test_tokenize_handles_special_cases
. tests/data/tokenizers/word_splitter_test.py::TestLettersDigitsWordSplitter::test_tokenize_handles_complex_punctuation
. tests/data/tokenizers/word_splitter_test.py::TestLettersDigitsWordSplitter::test_tokenize_handles_splits_all_punctuation
. tests/data/tokenizers/word_splitter_test.py::TestLettersDigitsWordSplitter::test_tokenize_handles_unicode_letters
. tests/data/tokenizers/word_splitter_test.py::TestSpacyWordSplitter::test_tokenize_handles_complex_punctuation
F tests/data/tokenizers/word_splitter_test.py::TestSpacyWordSplitter::test_tokenize_handles_contraction
 self = <tests.data.tokenizers.word_splitter_test.TestSpacyWordSplitter testMethod=test_tokenize_handles_contraction>
 
     def test_tokenize_handles_contraction(self):
         # note that "would've" is kept together, while "ain't" is not.
         sentence = "it ain't joe's problem; would've been yesterday"
         expected_tokens = ["it", "ai", "n't", "joe", "'s", "problem", ";", "would've", "been",
                            "yesterday"]
         tokens = [t.text for t in self.word_splitter.split_words(sentence)]
 >       assert tokens == expected_tokens
 E       AssertionError: assert ['it', 'ai', ...problem', ...] == ['it', 'ai', "...problem', ...]
 E         At index 7 diff: 'would' != "would've"
 E         Left contains more items, first extra item: 'yesterday'
 E         Use -v to get the full diff
 
 tests/data/tokenizers/word_splitter_test.py:99: AssertionError
. tests/data/tokenizers/word_splitter_test.py::TestSpacyWordSplitter::test_tokenize_handles_final_apostrophe
. tests/data/tokenizers/word_splitter_test.py::TestSpacyWordSplitter::test_tokenize_handles_multiple_contraction
. tests/data/tokenizers/word_splitter_test.py::TestSpacyWordSplitter::test_tokenize_handles_special_cases
. tests/data/tokenizers/word_splitter_test.py::TestSpacyWordSplitter::test_tokenize_removes_whitespace_tokens
. tests/data/tokenizers/word_tokenizer_test.py::TestWordTokenizer::test_passes_through_correctly
. tests/data/tokenizers/word_tokenizer_test.py::TestWordTokenizer::test_stems_and_filters_correctly
. tests/models/archival_test.py::ArchivalTest::test_archiving
. tests/models/archival_test.py::ArchivalTest::test_extra_files
. tests/models/crf_tagger_test.py::CrfTaggerTest::test_batch_predictions_are_consistent
. tests/models/crf_tagger_test.py::CrfTaggerTest::test_forward_pass_runs_correctly
. tests/models/crf_tagger_test.py::CrfTaggerTest::test_mismatching_dimensions_throws_configuration_error
. tests/models/crf_tagger_test.py::CrfTaggerTest::test_simple_tagger_can_train_save_and_load
. tests/models/decomposable_attention_test.py::TestDecomposableAttention::test_batch_predictions_are_consistent
. tests/models/decomposable_attention_test.py::TestDecomposableAttention::test_forward_pass_runs_correctly
. tests/models/decomposable_attention_test.py::TestDecomposableAttention::test_mismatched_dimensions_raise_configuration_errors
. tests/models/decomposable_attention_test.py::TestDecomposableAttention::test_model_can_train_save_and_load
. tests/models/decomposable_attention_test.py::TestDecomposableAttention::test_model_load
. tests/models/semantic_role_labeler_test.py::SemanticRoleLabelerTest::test_batch_predictions_are_consistent
. tests/models/semantic_role_labeler_test.py::SemanticRoleLabelerTest::test_bio_tags_correctly_convert_to_conll_format
. tests/models/semantic_role_labeler_test.py::SemanticRoleLabelerTest::test_decode_runs_correctly
. tests/models/semantic_role_labeler_test.py::SemanticRoleLabelerTest::test_forward_pass_runs_correctly
. tests/models/semantic_role_labeler_test.py::SemanticRoleLabelerTest::test_mismatching_dimensions_throws_configuration_error
. tests/models/semantic_role_labeler_test.py::SemanticRoleLabelerTest::test_perl_eval_script_can_run_on_printed_conll_files
. tests/models/semantic_role_labeler_test.py::SemanticRoleLabelerTest::test_srl_model_can_train_save_and_load
. tests/models/simple_tagger_test.py::SimpleTaggerTest::test_batch_predictions_are_consistent
. tests/models/simple_tagger_test.py::SimpleTaggerTest::test_forward_pass_runs_correctly
. tests/models/simple_tagger_test.py::SimpleTaggerTest::test_mismatching_dimensions_throws_configuration_error
. tests/models/simple_tagger_test.py::SimpleTaggerTest::test_regularization
. tests/models/simple_tagger_test.py::SimpleTaggerTest::test_simple_tagger_can_train_save_and_load
F tests/models/simple_tagger_test.py::SimpleTaggerRegularizationTest::test_regularization
 self = <tests.models.simple_tagger_test.SimpleTaggerRegularizationTest testMethod=test_regularization>
 
     def setUp(self):
         super().setUp()
         param_file = 'tests/fixtures/simple_tagger/experiment_with_regularization.json'
         self.set_up_model(param_file,
                           'tests/fixtures/data/sequence_tagging.tsv')
         params = Params.from_file(param_file)
         self.reader = DatasetReader.from_params(params['dataset_reader'])
         self.iterator = DataIterator.from_params(params['iterator'])
         self.trainer = Trainer.from_params(
                 self.model,
                 self.TEST_DIR,
                 self.iterator,
                 self.dataset,
                 None,
 >               params.get('trainer')
         )
 E       TypeError: from_params() missing 1 required positional argument: 'files_to_archive'
 
 tests/models/simple_tagger_test.py:81: TypeError
. tests/models/sniff_test.py::SniffTest::test_config
. tests/models/sniff_test.py::SniffTest::test_coreference_resolution
. tests/models/sniff_test.py::SniffTest::test_machine_comprehension
. tests/models/sniff_test.py::SniffTest::test_ner
. tests/models/sniff_test.py::SniffTest::test_semantic_role_labeling
. tests/models/sniff_test.py::SniffTest::test_textual_entailment
. tests/models/coreference_resolution/coref_test.py::CorefTest::test_coref_model_can_train_save_and_load
. tests/models/coreference_resolution/coref_test.py::CorefTest::test_decode
. tests/models/encoder_decoders/simple_seq2seq_test.py::SimpleSeq2SeqWithoutAttentionTest::test_decode_runs_correctly
. tests/models/encoder_decoders/simple_seq2seq_test.py::SimpleSeq2SeqWithoutAttentionTest::test_encoder_decoder_can_train_save_and_load
. tests/models/encoder_decoders/simple_seq2seq_test.py::SimpleSeq2SeqWithoutAttentionTest::test_loss_is_computed_correctly
. tests/models/encoder_decoders/simple_seq2seq_test.py::SimpleSeq2SeqWithAttentionTest::test_encoder_decoder_can_train_save_and_load
. tests/models/reading_comprehension/bidaf_test.py::BidirectionalAttentionFlowTest::test_batch_predictions_are_consistent
. tests/models/reading_comprehension/bidaf_test.py::BidirectionalAttentionFlowTest::test_forward_pass_runs_correctly
. tests/models/reading_comprehension/bidaf_test.py::BidirectionalAttentionFlowTest::test_get_best_span
. tests/models/reading_comprehension/bidaf_test.py::BidirectionalAttentionFlowTest::test_mismatching_dimensions_throws_configuration_error
. tests/models/reading_comprehension/bidaf_test.py::BidirectionalAttentionFlowTest::test_model_can_train_save_and_load
F tests/models/span_srl/frame_semi_crf_srl_test.py::FrameSemiCrfSemanticRoleLabelerTest::testMakeSpanMask
 self = <frame_semi_crf_srl_test.FrameSemiCrfSemanticRoleLabelerTest testMethod=testMakeSpanMask>
 
     def testMakeSpanMask(self):
         # TODO(Swabha): Check if a tensor like this is actually getting generated in framenet-reader-test.
         valid_frame_elements = Variable(torch.LongTensor(
 >           [[1, 2, 3, 4, 9], [7, 7, -1, -1, -1]]).cuda())
 
 tests/models/span_srl/frame_semi_crf_srl_test.py:19: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/_utils.py:69: in _cuda
     return new_type(self.size()).copy_(self, async)
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:358: in _lazy_new
     _lazy_init()
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:120: in _lazy_init
     _check_driver()
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
     def _check_driver():
         if not hasattr(torch._C, '_cuda_isDriverSufficient'):
 >           raise AssertionError("Torch not compiled with CUDA enabled")
 E           AssertionError: Torch not compiled with CUDA enabled
 
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:55: AssertionError
F tests/models/span_srl/semi_crf_srl_test.py::SemiCrfSemanticRoleLabelerTest::test_batch_predictions_are_consistent
 self = <semi_crf_srl_test.SemiCrfSemanticRoleLabelerTest testMethod=test_batch_predictions_are_consistent>
 
     def setUp(self):
         super(SemiCrfSemanticRoleLabelerTest, self).setUp()
         self.set_up_model(
 >           'tests/fixtures/crf_srl/experiment.json', 'tests/fixtures/conll_2012')
 
 tests/models/span_srl/semi_crf_srl_test.py:20: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 allennlp/common/testing/model_test_case.py:21: in set_up_model
     params = Params.from_file(self.param_file)
 allennlp/common/params.py:230: in from_file
     params_file = cached_path(params_file)
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
 url_or_filename = 'tests/fixtures/crf_srl/experiment.json', cache_dir = '/Users/malcolm/.allennlp/datasets'
 
     def cached_path(url_or_filename: str, cache_dir: str = None) -> str:
         """
         Given something that might be a URL (or might be a local path),
         determine which. If it's a URL, download the file and cache it, and
         return the path to the cached file. If it's already a local path,
         make sure the file exists and then return the path.
         """
         if cache_dir is None:
             cache_dir = DATASET_CACHE
     
         parsed = urlparse(url_or_filename)
     
         if parsed.scheme in ('http', 'https'):
             # URL, so get it from the cache (downloading if necessary)
             return get_from_cache(url_or_filename, cache_dir)
         elif parsed.scheme == '' and os.path.exists(url_or_filename):
             # File, and it exists.
             return url_or_filename
         elif parsed.scheme == '':
             # File, but it doesn't exist.
 >           raise FileNotFoundError("file {} not found".format(url_or_filename))
 E           FileNotFoundError: file tests/fixtures/crf_srl/experiment.json not found
 
 allennlp/common/file_utils.py:75: FileNotFoundError
F tests/models/span_srl/semi_crf_srl_test.py::SemiCrfSemanticRoleLabelerTest::test_crf_srl_model_can_train_save_and_load
 self = <semi_crf_srl_test.SemiCrfSemanticRoleLabelerTest testMethod=test_crf_srl_model_can_train_save_and_load>
 
     def setUp(self):
         super(SemiCrfSemanticRoleLabelerTest, self).setUp()
         self.set_up_model(
 >           'tests/fixtures/crf_srl/experiment.json', 'tests/fixtures/conll_2012')
 
 tests/models/span_srl/semi_crf_srl_test.py:20: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 allennlp/common/testing/model_test_case.py:21: in set_up_model
     params = Params.from_file(self.param_file)
 allennlp/common/params.py:230: in from_file
     params_file = cached_path(params_file)
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
 url_or_filename = 'tests/fixtures/crf_srl/experiment.json', cache_dir = '/Users/malcolm/.allennlp/datasets'
 
     def cached_path(url_or_filename: str, cache_dir: str = None) -> str:
         """
         Given something that might be a URL (or might be a local path),
         determine which. If it's a URL, download the file and cache it, and
         return the path to the cached file. If it's already a local path,
         make sure the file exists and then return the path.
         """
         if cache_dir is None:
             cache_dir = DATASET_CACHE
     
         parsed = urlparse(url_or_filename)
     
         if parsed.scheme in ('http', 'https'):
             # URL, so get it from the cache (downloading if necessary)
             return get_from_cache(url_or_filename, cache_dir)
         elif parsed.scheme == '' and os.path.exists(url_or_filename):
             # File, and it exists.
             return url_or_filename
         elif parsed.scheme == '':
             # File, but it doesn't exist.
 >           raise FileNotFoundError("file {} not found".format(url_or_filename))
 E           FileNotFoundError: file tests/fixtures/crf_srl/experiment.json not found
 
 allennlp/common/file_utils.py:75: FileNotFoundError
F tests/models/span_srl/semi_crf_srl_test.py::SemiCrfSemanticRoleLabelerTest::test_decode_runs_correctly
 self = <semi_crf_srl_test.SemiCrfSemanticRoleLabelerTest testMethod=test_decode_runs_correctly>
 
     def setUp(self):
         super(SemiCrfSemanticRoleLabelerTest, self).setUp()
         self.set_up_model(
 >           'tests/fixtures/crf_srl/experiment.json', 'tests/fixtures/conll_2012')
 
 tests/models/span_srl/semi_crf_srl_test.py:20: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 allennlp/common/testing/model_test_case.py:21: in set_up_model
     params = Params.from_file(self.param_file)
 allennlp/common/params.py:230: in from_file
     params_file = cached_path(params_file)
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
 url_or_filename = 'tests/fixtures/crf_srl/experiment.json', cache_dir = '/Users/malcolm/.allennlp/datasets'
 
     def cached_path(url_or_filename: str, cache_dir: str = None) -> str:
         """
         Given something that might be a URL (or might be a local path),
         determine which. If it's a URL, download the file and cache it, and
         return the path to the cached file. If it's already a local path,
         make sure the file exists and then return the path.
         """
         if cache_dir is None:
             cache_dir = DATASET_CACHE
     
         parsed = urlparse(url_or_filename)
     
         if parsed.scheme in ('http', 'https'):
             # URL, so get it from the cache (downloading if necessary)
             return get_from_cache(url_or_filename, cache_dir)
         elif parsed.scheme == '' and os.path.exists(url_or_filename):
             # File, and it exists.
             return url_or_filename
         elif parsed.scheme == '':
             # File, but it doesn't exist.
 >           raise FileNotFoundError("file {} not found".format(url_or_filename))
 E           FileNotFoundError: file tests/fixtures/crf_srl/experiment.json not found
 
 allennlp/common/file_utils.py:75: FileNotFoundError
F tests/models/span_srl/semi_crf_srl_test.py::SemiCrfSemanticRoleLabelerTest::test_forward_pass_runs_correctly
 self = <semi_crf_srl_test.SemiCrfSemanticRoleLabelerTest testMethod=test_forward_pass_runs_correctly>
 
     def setUp(self):
         super(SemiCrfSemanticRoleLabelerTest, self).setUp()
         self.set_up_model(
 >           'tests/fixtures/crf_srl/experiment.json', 'tests/fixtures/conll_2012')
 
 tests/models/span_srl/semi_crf_srl_test.py:20: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 allennlp/common/testing/model_test_case.py:21: in set_up_model
     params = Params.from_file(self.param_file)
 allennlp/common/params.py:230: in from_file
     params_file = cached_path(params_file)
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
 url_or_filename = 'tests/fixtures/crf_srl/experiment.json', cache_dir = '/Users/malcolm/.allennlp/datasets'
 
     def cached_path(url_or_filename: str, cache_dir: str = None) -> str:
         """
         Given something that might be a URL (or might be a local path),
         determine which. If it's a URL, download the file and cache it, and
         return the path to the cached file. If it's already a local path,
         make sure the file exists and then return the path.
         """
         if cache_dir is None:
             cache_dir = DATASET_CACHE
     
         parsed = urlparse(url_or_filename)
     
         if parsed.scheme in ('http', 'https'):
             # URL, so get it from the cache (downloading if necessary)
             return get_from_cache(url_or_filename, cache_dir)
         elif parsed.scheme == '' and os.path.exists(url_or_filename):
             # File, and it exists.
             return url_or_filename
         elif parsed.scheme == '':
             # File, but it doesn't exist.
 >           raise FileNotFoundError("file {} not found".format(url_or_filename))
 E           FileNotFoundError: file tests/fixtures/crf_srl/experiment.json not found
 
 allennlp/common/file_utils.py:75: FileNotFoundError
F tests/models/span_srl/semi_crf_srl_test.py::SemiCrfSemanticRoleLabelerTest::test_mismatching_dimensions_throws_configuration_error
 self = <semi_crf_srl_test.SemiCrfSemanticRoleLabelerTest testMethod=test_mismatching_dimensions_throws_configuration_error>
 
     def setUp(self):
         super(SemiCrfSemanticRoleLabelerTest, self).setUp()
         self.set_up_model(
 >           'tests/fixtures/crf_srl/experiment.json', 'tests/fixtures/conll_2012')
 
 tests/models/span_srl/semi_crf_srl_test.py:20: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 allennlp/common/testing/model_test_case.py:21: in set_up_model
     params = Params.from_file(self.param_file)
 allennlp/common/params.py:230: in from_file
     params_file = cached_path(params_file)
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
 url_or_filename = 'tests/fixtures/crf_srl/experiment.json', cache_dir = '/Users/malcolm/.allennlp/datasets'
 
     def cached_path(url_or_filename: str, cache_dir: str = None) -> str:
         """
         Given something that might be a URL (or might be a local path),
         determine which. If it's a URL, download the file and cache it, and
         return the path to the cached file. If it's already a local path,
         make sure the file exists and then return the path.
         """
         if cache_dir is None:
             cache_dir = DATASET_CACHE
     
         parsed = urlparse(url_or_filename)
     
         if parsed.scheme in ('http', 'https'):
             # URL, so get it from the cache (downloading if necessary)
             return get_from_cache(url_or_filename, cache_dir)
         elif parsed.scheme == '' and os.path.exists(url_or_filename):
             # File, and it exists.
             return url_or_filename
         elif parsed.scheme == '':
             # File, but it doesn't exist.
 >           raise FileNotFoundError("file {} not found".format(url_or_filename))
 E           FileNotFoundError: file tests/fixtures/crf_srl/experiment.json not found
 
 allennlp/common/file_utils.py:75: FileNotFoundError
. tests/modules/attention_test.py::TestAttention::test_batched_masked
. tests/modules/attention_test.py::TestAttention::test_batched_no_mask
. tests/modules/attention_test.py::TestAttention::test_can_build_from_params
. tests/modules/attention_test.py::TestAttention::test_masked
. tests/modules/attention_test.py::TestAttention::test_no_mask
. tests/modules/attention_test.py::TestAttention::test_non_normalized_attention_works
. tests/modules/augmented_lstm_test.py::TestAugmentedLSTM::test_augmented_lstm_computes_same_function_as_pytorch_lstm
. tests/modules/augmented_lstm_test.py::TestAugmentedLSTM::test_augmented_lstm_is_initialized_with_correct_biases
. tests/modules/augmented_lstm_test.py::TestAugmentedLSTM::test_augmented_lstm_throws_error_on_non_packed_sequence_input
. tests/modules/augmented_lstm_test.py::TestAugmentedLSTM::test_augmented_lstm_works_with_highway_connections
. tests/modules/augmented_lstm_test.py::TestAugmentedLSTM::test_variable_length_sequences_return_correctly_padded_outputs
. tests/modules/augmented_lstm_test.py::TestAugmentedLSTM::test_variable_length_sequences_run_backward_return_correctly_padded_outputs
. tests/modules/conditional_random_field_test.py::TestConditionalRandomField::test_forward_works_with_mask
. tests/modules/conditional_random_field_test.py::TestConditionalRandomField::test_forward_works_without_mask
. tests/modules/conditional_random_field_test.py::TestConditionalRandomField::test_viterbi_tags
. tests/modules/elmo_test.py::TestElmoBiLm::test_elmo_bilm
. tests/modules/elmo_test.py::TestElmo::test_elmo
. tests/modules/elmo_test.py::TestElmo::test_elmo_4D_input
. tests/modules/elmo_test.py::TestElmoTokenRepresentation::test_elmo_token_representation
. tests/modules/elmo_test.py::TestElmoTokenRepresentation::test_elmo_token_representation_bos_eos
. tests/modules/encoder_base_test.py::TestEncoderBase::test_get_initial_states
. tests/modules/encoder_base_test.py::TestEncoderBase::test_non_stateful_states_are_sorted_correctly
. tests/modules/encoder_base_test.py::TestEncoderBase::test_update_states
. tests/modules/feedforward_test.py::TestFeedForward::test_forward_gives_correct_output
. tests/modules/feedforward_test.py::TestFeedForward::test_init_checks_activation_consistency
. tests/modules/feedforward_test.py::TestFeedForward::test_init_checks_hidden_dim_consistency
. tests/modules/highway_test.py::TestHighway::test_forward_works_on_simple_input
. tests/modules/lstm_cell_with_projection_test.py::TestLstmCellWithProjection::test_elmo_lstm_cell_completes_forward_pass
. tests/modules/matrix_attention_test.py::TestMatrixAttention::test_can_build_from_params
. tests/modules/matrix_attention_test.py::TestMatrixAttention::test_forward_works_on_simple_input
. tests/modules/scalar_mix_test.py::TestScalarMix::test_scalar_mix_can_run_forward
. tests/modules/scalar_mix_test.py::TestScalarMix::test_scalar_mix_layer_norm
. tests/modules/scalar_mix_test.py::TestScalarMix::test_scalar_mix_throws_error_on_incorrect_number_of_inputs
F tests/modules/semi_markov_crf_test.py::TestSemiMarkovConditionalRandomField::test_forward
 self = <tests.modules.semi_markov_crf_test.TestSemiMarkovConditionalRandomField testMethod=test_forward>
 
     def setUp(self):
         super().setUp()
         self.batch_size = 2
         self.sentence_len = 3
         self.max_segment_length = 2
         self.num_tags = 3  # for [A, B, *]
         ninf = -500.0
         self.logits = Variable(torch.Tensor([
             [[[0.20, 0.35, 0.00], [ninf, ninf, ninf]],
              [[0.30, 0.16, 0.10], [1.20, 0.05, 0.00]],
              [[0.10, 1.80, ninf], [0.00, 0.10, 0.00]]],
     
             [[[0.40, 2.00, 0.00], [ninf, ninf, ninf]],
              [[1.80, 0.40, 0.00], [0.30, 0.10, 0.00]],
 >            [[ninf, ninf, ninf], [ninf, ninf, ninf]]]
         ]).cuda())
 
 tests/modules/semi_markov_crf_test.py:32: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/_utils.py:69: in _cuda
     return new_type(self.size()).copy_(self, async)
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:358: in _lazy_new
     _lazy_init()
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:120: in _lazy_init
     _check_driver()
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
     def _check_driver():
         if not hasattr(torch._C, '_cuda_isDriverSufficient'):
 >           raise AssertionError("Torch not compiled with CUDA enabled")
 E           AssertionError: Torch not compiled with CUDA enabled
 
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:55: AssertionError
F tests/modules/semi_markov_crf_test.py::TestSemiMarkovConditionalRandomField::test_forward_with_tag_mask
 self = <tests.modules.semi_markov_crf_test.TestSemiMarkovConditionalRandomField testMethod=test_forward_with_tag_mask>
 
     def setUp(self):
         super().setUp()
         self.batch_size = 2
         self.sentence_len = 3
         self.max_segment_length = 2
         self.num_tags = 3  # for [A, B, *]
         ninf = -500.0
         self.logits = Variable(torch.Tensor([
             [[[0.20, 0.35, 0.00], [ninf, ninf, ninf]],
              [[0.30, 0.16, 0.10], [1.20, 0.05, 0.00]],
              [[0.10, 1.80, ninf], [0.00, 0.10, 0.00]]],
     
             [[[0.40, 2.00, 0.00], [ninf, ninf, ninf]],
              [[1.80, 0.40, 0.00], [0.30, 0.10, 0.00]],
 >            [[ninf, ninf, ninf], [ninf, ninf, ninf]]]
         ]).cuda())
 
 tests/modules/semi_markov_crf_test.py:32: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/_utils.py:69: in _cuda
     return new_type(self.size()).copy_(self, async)
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:358: in _lazy_new
     _lazy_init()
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:120: in _lazy_init
     _check_driver()
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
     def _check_driver():
         if not hasattr(torch._C, '_cuda_isDriverSufficient'):
 >           raise AssertionError("Torch not compiled with CUDA enabled")
 E           AssertionError: Torch not compiled with CUDA enabled
 
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:55: AssertionError
F tests/modules/semi_markov_crf_test.py::TestSemiMarkovConditionalRandomField::test_hamming_cost
 self = <tests.modules.semi_markov_crf_test.TestSemiMarkovConditionalRandomField testMethod=test_hamming_cost>
 
     def setUp(self):
         super().setUp()
         self.batch_size = 2
         self.sentence_len = 3
         self.max_segment_length = 2
         self.num_tags = 3  # for [A, B, *]
         ninf = -500.0
         self.logits = Variable(torch.Tensor([
             [[[0.20, 0.35, 0.00], [ninf, ninf, ninf]],
              [[0.30, 0.16, 0.10], [1.20, 0.05, 0.00]],
              [[0.10, 1.80, ninf], [0.00, 0.10, 0.00]]],
     
             [[[0.40, 2.00, 0.00], [ninf, ninf, ninf]],
              [[1.80, 0.40, 0.00], [0.30, 0.10, 0.00]],
 >            [[ninf, ninf, ninf], [ninf, ninf, ninf]]]
         ]).cuda())
 
 tests/modules/semi_markov_crf_test.py:32: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/_utils.py:69: in _cuda
     return new_type(self.size()).copy_(self, async)
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:358: in _lazy_new
     _lazy_init()
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:120: in _lazy_init
     _check_driver()
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
     def _check_driver():
         if not hasattr(torch._C, '_cuda_isDriverSufficient'):
 >           raise AssertionError("Torch not compiled with CUDA enabled")
 E           AssertionError: Torch not compiled with CUDA enabled
 
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:55: AssertionError
F tests/modules/semi_markov_crf_test.py::TestSemiMarkovConditionalRandomField::test_recall_oriented_cost
 self = <tests.modules.semi_markov_crf_test.TestSemiMarkovConditionalRandomField testMethod=test_recall_oriented_cost>
 
     def setUp(self):
         super().setUp()
         self.batch_size = 2
         self.sentence_len = 3
         self.max_segment_length = 2
         self.num_tags = 3  # for [A, B, *]
         ninf = -500.0
         self.logits = Variable(torch.Tensor([
             [[[0.20, 0.35, 0.00], [ninf, ninf, ninf]],
              [[0.30, 0.16, 0.10], [1.20, 0.05, 0.00]],
              [[0.10, 1.80, ninf], [0.00, 0.10, 0.00]]],
     
             [[[0.40, 2.00, 0.00], [ninf, ninf, ninf]],
              [[1.80, 0.40, 0.00], [0.30, 0.10, 0.00]],
 >            [[ninf, ninf, ninf], [ninf, ninf, ninf]]]
         ]).cuda())
 
 tests/modules/semi_markov_crf_test.py:32: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/_utils.py:69: in _cuda
     return new_type(self.size()).copy_(self, async)
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:358: in _lazy_new
     _lazy_init()
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:120: in _lazy_init
     _check_driver()
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
     def _check_driver():
         if not hasattr(torch._C, '_cuda_isDriverSufficient'):
 >           raise AssertionError("Torch not compiled with CUDA enabled")
 E           AssertionError: Torch not compiled with CUDA enabled
 
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:55: AssertionError
F tests/modules/semi_markov_crf_test.py::TestSemiMarkovConditionalRandomField::test_roc_loss
 self = <tests.modules.semi_markov_crf_test.TestSemiMarkovConditionalRandomField testMethod=test_roc_loss>
 
     def setUp(self):
         super().setUp()
         self.batch_size = 2
         self.sentence_len = 3
         self.max_segment_length = 2
         self.num_tags = 3  # for [A, B, *]
         ninf = -500.0
         self.logits = Variable(torch.Tensor([
             [[[0.20, 0.35, 0.00], [ninf, ninf, ninf]],
              [[0.30, 0.16, 0.10], [1.20, 0.05, 0.00]],
              [[0.10, 1.80, ninf], [0.00, 0.10, 0.00]]],
     
             [[[0.40, 2.00, 0.00], [ninf, ninf, ninf]],
              [[1.80, 0.40, 0.00], [0.30, 0.10, 0.00]],
 >            [[ninf, ninf, ninf], [ninf, ninf, ninf]]]
         ]).cuda())
 
 tests/modules/semi_markov_crf_test.py:32: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/_utils.py:69: in _cuda
     return new_type(self.size()).copy_(self, async)
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:358: in _lazy_new
     _lazy_init()
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:120: in _lazy_init
     _check_driver()
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
     def _check_driver():
         if not hasattr(torch._C, '_cuda_isDriverSufficient'):
 >           raise AssertionError("Torch not compiled with CUDA enabled")
 E           AssertionError: Torch not compiled with CUDA enabled
 
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:55: AssertionError
F tests/modules/semi_markov_crf_test.py::TestSemiMarkovConditionalRandomField::test_simple_recall_cost
 self = <tests.modules.semi_markov_crf_test.TestSemiMarkovConditionalRandomField testMethod=test_simple_recall_cost>
 
     def setUp(self):
         super().setUp()
         self.batch_size = 2
         self.sentence_len = 3
         self.max_segment_length = 2
         self.num_tags = 3  # for [A, B, *]
         ninf = -500.0
         self.logits = Variable(torch.Tensor([
             [[[0.20, 0.35, 0.00], [ninf, ninf, ninf]],
              [[0.30, 0.16, 0.10], [1.20, 0.05, 0.00]],
              [[0.10, 1.80, ninf], [0.00, 0.10, 0.00]]],
     
             [[[0.40, 2.00, 0.00], [ninf, ninf, ninf]],
              [[1.80, 0.40, 0.00], [0.30, 0.10, 0.00]],
 >            [[ninf, ninf, ninf], [ninf, ninf, ninf]]]
         ]).cuda())
 
 tests/modules/semi_markov_crf_test.py:32: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/_utils.py:69: in _cuda
     return new_type(self.size()).copy_(self, async)
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:358: in _lazy_new
     _lazy_init()
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:120: in _lazy_init
     _check_driver()
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
     def _check_driver():
         if not hasattr(torch._C, '_cuda_isDriverSufficient'):
 >           raise AssertionError("Torch not compiled with CUDA enabled")
 E           AssertionError: Torch not compiled with CUDA enabled
 
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:55: AssertionError
F tests/modules/semi_markov_crf_test.py::TestSemiMarkovConditionalRandomField::test_viterbi_tags
 self = <tests.modules.semi_markov_crf_test.TestSemiMarkovConditionalRandomField testMethod=test_viterbi_tags>
 
     def setUp(self):
         super().setUp()
         self.batch_size = 2
         self.sentence_len = 3
         self.max_segment_length = 2
         self.num_tags = 3  # for [A, B, *]
         ninf = -500.0
         self.logits = Variable(torch.Tensor([
             [[[0.20, 0.35, 0.00], [ninf, ninf, ninf]],
              [[0.30, 0.16, 0.10], [1.20, 0.05, 0.00]],
              [[0.10, 1.80, ninf], [0.00, 0.10, 0.00]]],
     
             [[[0.40, 2.00, 0.00], [ninf, ninf, ninf]],
              [[1.80, 0.40, 0.00], [0.30, 0.10, 0.00]],
 >            [[ninf, ninf, ninf], [ninf, ninf, ninf]]]
         ]).cuda())
 
 tests/modules/semi_markov_crf_test.py:32: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/_utils.py:69: in _cuda
     return new_type(self.size()).copy_(self, async)
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:358: in _lazy_new
     _lazy_init()
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:120: in _lazy_init
     _check_driver()
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
     def _check_driver():
         if not hasattr(torch._C, '_cuda_isDriverSufficient'):
 >           raise AssertionError("Torch not compiled with CUDA enabled")
 E           AssertionError: Torch not compiled with CUDA enabled
 
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:55: AssertionError
F tests/modules/semi_markov_crf_test.py::TestSemiMarkovConditionalRandomField::test_viterbi_tags_merging
 self = <tests.modules.semi_markov_crf_test.TestSemiMarkovConditionalRandomField testMethod=test_viterbi_tags_merging>
 
     def setUp(self):
         super().setUp()
         self.batch_size = 2
         self.sentence_len = 3
         self.max_segment_length = 2
         self.num_tags = 3  # for [A, B, *]
         ninf = -500.0
         self.logits = Variable(torch.Tensor([
             [[[0.20, 0.35, 0.00], [ninf, ninf, ninf]],
              [[0.30, 0.16, 0.10], [1.20, 0.05, 0.00]],
              [[0.10, 1.80, ninf], [0.00, 0.10, 0.00]]],
     
             [[[0.40, 2.00, 0.00], [ninf, ninf, ninf]],
              [[1.80, 0.40, 0.00], [0.30, 0.10, 0.00]],
 >            [[ninf, ninf, ninf], [ninf, ninf, ninf]]]
         ]).cuda())
 
 tests/modules/semi_markov_crf_test.py:32: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/_utils.py:69: in _cuda
     return new_type(self.size()).copy_(self, async)
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:358: in _lazy_new
     _lazy_init()
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:120: in _lazy_init
     _check_driver()
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
     def _check_driver():
         if not hasattr(torch._C, '_cuda_isDriverSufficient'):
 >           raise AssertionError("Torch not compiled with CUDA enabled")
 E           AssertionError: Torch not compiled with CUDA enabled
 
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/site-packages/torch/cuda/__init__.py:55: AssertionError
. tests/modules/seq2seq_encoder_test.py::TestSeq2SeqEncoder::test_from_params_builders_encoder_correctly
. tests/modules/seq2seq_encoder_test.py::TestSeq2SeqEncoder::test_from_params_requires_batch_first
. tests/modules/seq2vec_encoder_test.py::TestSeq2VecEncoder::test_from_params_builders_encoder_correctly
. tests/modules/seq2vec_encoder_test.py::TestSeq2VecEncoder::test_from_params_requires_batch_first
. tests/modules/stacked_alternating_lstm_test.py::TestStackedAlternatingLstm::test_lstms_are_interleaved
. tests/modules/stacked_alternating_lstm_test.py::TestStackedAlternatingLstm::test_stacked_alternating_lstm_completes_forward_pass
. tests/modules/stacked_elmo_lstm_test.py::TestElmoLstmCell::test_elmo_lstm
. tests/modules/time_distributed_test.py::TestTimeDistributed::test_time_distributed_reshapes_correctly
. tests/modules/time_distributed_test.py::TestTimeDistributed::test_time_distributed_works_with_multiple_inputs
. tests/modules/seq2seq_encoders/intra_sentence_attention_test.py::TestIntraSentenceAttentionEncoder::test_constructor_asserts_multi_head_consistency
. tests/modules/seq2seq_encoders/intra_sentence_attention_test.py::TestIntraSentenceAttentionEncoder::test_forward_works_with_multi_headed_attention
. tests/modules/seq2seq_encoders/intra_sentence_attention_test.py::TestIntraSentenceAttentionEncoder::test_forward_works_with_simple_attention
. tests/modules/seq2seq_encoders/intra_sentence_attention_test.py::TestIntraSentenceAttentionEncoder::test_get_dimension_is_correct
. tests/modules/seq2seq_encoders/multi_head_self_attention_test.py::MultiHeadSelfAttentionTest::test_multi_head_self_attention_respects_masking
. tests/modules/seq2seq_encoders/multi_head_self_attention_test.py::MultiHeadSelfAttentionTest::test_multi_head_self_attention_runs_forward
. tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py::TestPytorchSeq2SeqWrapper::test_forward_does_not_compress_tensors_padded_to_greater_than_the_max_sequence_length
. tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py::TestPytorchSeq2SeqWrapper::test_forward_pulls_out_correct_tensor_for_unsorted_batches
. tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py::TestPytorchSeq2SeqWrapper::test_forward_pulls_out_correct_tensor_with_sequence_lengths
. tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py::TestPytorchSeq2SeqWrapper::test_forward_pulls_out_correct_tensor_without_sequence_lengths
. tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py::TestPytorchSeq2SeqWrapper::test_forward_works_even_with_empty_sequences
. tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py::TestPytorchSeq2SeqWrapper::test_get_dimension_is_correct
. tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py::TestPytorchSeq2SeqWrapper::test_wrapper_can_call_backward_with_zero_length_sequences
. tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py::TestPytorchSeq2SeqWrapper::test_wrapper_raises_if_batch_first_is_false
. tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py::TestPytorchSeq2SeqWrapper::test_wrapper_stateful
. tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py::TestPytorchSeq2SeqWrapper::test_wrapper_stateful_single_state_gru
. tests/modules/seq2seq_encoders/pytorch_seq2seq_wrapper_test.py::TestPytorchSeq2SeqWrapper::test_wrapper_works_when_passed_state_with_zero_length_sequences
. tests/modules/seq2seq_encoders/stacked_self_attention_test.py::TestStackedSelfAttention::test_get_dimension_is_correct
. tests/modules/seq2seq_encoders/stacked_self_attention_test.py::TestStackedSelfAttention::test_stacked_self_attention_can_run_foward
. tests/modules/seq2vec_encoders/boe_encoder_test.py::TestBagOfEmbeddingsEncoder::test_can_construct_from_params
. tests/modules/seq2vec_encoders/boe_encoder_test.py::TestBagOfEmbeddingsEncoder::test_forward_does_correct_computation
. tests/modules/seq2vec_encoders/boe_encoder_test.py::TestBagOfEmbeddingsEncoder::test_forward_does_correct_computation_with_average
. tests/modules/seq2vec_encoders/boe_encoder_test.py::TestBagOfEmbeddingsEncoder::test_forward_does_correct_computation_with_average_no_mask
. tests/modules/seq2vec_encoders/boe_encoder_test.py::TestBagOfEmbeddingsEncoder::test_get_dimension_is_correct
. tests/modules/seq2vec_encoders/cnn_encoder_test.py::TestCnnEncoder::test_can_construct_from_params
. tests/modules/seq2vec_encoders/cnn_encoder_test.py::TestCnnEncoder::test_forward_does_correct_computation
. tests/modules/seq2vec_encoders/cnn_encoder_test.py::TestCnnEncoder::test_forward_runs_with_larger_input
. tests/modules/seq2vec_encoders/cnn_encoder_test.py::TestCnnEncoder::test_get_dimension_is_correct
. tests/modules/seq2vec_encoders/pytorch_seq2vec_wrapper_test.py::TestPytorchSeq2VecWrapper::test_forward_pulls_out_correct_tensor_with_sequence_lengths
. tests/modules/seq2vec_encoders/pytorch_seq2vec_wrapper_test.py::TestPytorchSeq2VecWrapper::test_forward_pulls_out_correct_tensor_with_unsorted_batches
. tests/modules/seq2vec_encoders/pytorch_seq2vec_wrapper_test.py::TestPytorchSeq2VecWrapper::test_forward_pulls_out_correct_tensor_without_sequence_lengths
. tests/modules/seq2vec_encoders/pytorch_seq2vec_wrapper_test.py::TestPytorchSeq2VecWrapper::test_forward_works_even_with_empty_sequences
. tests/modules/seq2vec_encoders/pytorch_seq2vec_wrapper_test.py::TestPytorchSeq2VecWrapper::test_get_dimensions_is_correct
. tests/modules/seq2vec_encoders/pytorch_seq2vec_wrapper_test.py::TestPytorchSeq2VecWrapper::test_wrapper_raises_if_batch_first_is_false
. tests/modules/similarity_functions/bilinear_test.py::TestBilinearSimilarityFunction::test_can_construct_from_params
. tests/modules/similarity_functions/bilinear_test.py::TestBilinearSimilarityFunction::test_forward_does_a_bilinear_product
. tests/modules/similarity_functions/bilinear_test.py::TestBilinearSimilarityFunction::test_forward_works_with_higher_order_tensors
. tests/modules/similarity_functions/bilinear_test.py::TestBilinearSimilarityFunction::test_weights_are_correct_sizes
. tests/modules/similarity_functions/cosine_test.py::TestCosineSimilarityFunction::test_can_construct_from_params
. tests/modules/similarity_functions/cosine_test.py::TestCosineSimilarityFunction::test_forward_does_a_cosine_similarity
. tests/modules/similarity_functions/cosine_test.py::TestCosineSimilarityFunction::test_forward_works_with_higher_order_tensors
. tests/modules/similarity_functions/dot_product_test.py::TestDotProductSimilarityFunction::test_can_construct_from_params
. tests/modules/similarity_functions/dot_product_test.py::TestDotProductSimilarityFunction::test_forward_does_a_dot_product
. tests/modules/similarity_functions/dot_product_test.py::TestDotProductSimilarityFunction::test_forward_works_with_higher_order_tensors
. tests/modules/similarity_functions/linear_test.py::TestLinearSimilarityFunction::test_can_construct_from_params
. tests/modules/similarity_functions/linear_test.py::TestLinearSimilarityFunction::test_forward_does_a_weighted_product
. tests/modules/similarity_functions/linear_test.py::TestLinearSimilarityFunction::test_forward_works_with_add_combinations
. tests/modules/similarity_functions/linear_test.py::TestLinearSimilarityFunction::test_forward_works_with_divide_combinations
. tests/modules/similarity_functions/linear_test.py::TestLinearSimilarityFunction::test_forward_works_with_higher_order_tensors
. tests/modules/similarity_functions/linear_test.py::TestLinearSimilarityFunction::test_forward_works_with_multiply_combinations
. tests/modules/similarity_functions/linear_test.py::TestLinearSimilarityFunction::test_forward_works_with_subtract_combinations
. tests/modules/similarity_functions/linear_test.py::TestLinearSimilarityFunction::test_weights_are_correct_sizes
. tests/modules/similarity_functions/multiheaded_test.py::TestMultiHeadedSimilarityFunction::test_forward
. tests/modules/similarity_functions/multiheaded_test.py::TestMultiHeadedSimilarityFunction::test_weights_are_correct_sizes
. tests/modules/text_field_embedders/basic_token_embedder_test.py::TestBasicTextFieldEmbedder::test_forward_asserts_input_field_match
. tests/modules/text_field_embedders/basic_token_embedder_test.py::TestBasicTextFieldEmbedder::test_forward_concats_resultant_embeddings
. tests/modules/text_field_embedders/basic_token_embedder_test.py::TestBasicTextFieldEmbedder::test_get_output_dim_aggregates_dimension_from_each_embedding
. tests/modules/token_embedders/elmo_token_embedder_test.py::TestElmoTokenEmbedder::test_file_archiving
. tests/modules/token_embedders/elmo_token_embedder_test.py::TestElmoTokenEmbedder::test_tagger_with_elmo_token_embedder_can_train_save_and_load
. tests/modules/token_embedders/elmo_token_embedder_test.py::TestElmoTokenEmbedder::test_tagger_with_elmo_token_embedder_forward_pass_runs_correctly
. tests/modules/token_embedders/embedding_test.py::TestEmbedding::test_embedding_layer_actually_initializes_word_vectors_correctly
. tests/modules/token_embedders/embedding_test.py::TestEmbedding::test_forward_works_with_projection_layer
. tests/modules/token_embedders/embedding_test.py::TestEmbedding::test_get_embedding_layer_initializes_unseen_words_randomly_not_zero
. tests/modules/token_embedders/embedding_test.py::TestEmbedding::test_get_embedding_layer_uses_correct_embedding_dim
. tests/modules/token_embedders/embedding_test.py::TestEmbedding::test_read_hdf5_format_file
. tests/modules/token_embedders/embedding_test.py::TestEmbedding::test_read_hdf5_raises_on_invalid_shape
. tests/modules/token_embedders/token_characters_encoder_test.py::TestTokenCharactersEncoder::test_forward_applies_embedding_then_encoder
. tests/modules/token_embedders/token_characters_encoder_test.py::TestTokenCharactersEncoder::test_get_output_dim_uses_encoder_output_dim
. tests/nn/initializers_test.py::TestInitializers::test_block_orthogonal_can_initialize
. tests/nn/initializers_test.py::TestInitializers::test_block_orthogonal_raises_on_mismatching_dimensions
. tests/nn/initializers_test.py::TestInitializers::test_regex_matches_are_initialized_correctly
. tests/nn/initializers_test.py::TestInitializers::test_uniform_unit_scaling_can_initialize
. tests/nn/regularizers_test.py::TestRegularizers::test_from_params
. tests/nn/regularizers_test.py::TestRegularizers::test_l1_regularization
. tests/nn/regularizers_test.py::TestRegularizers::test_l2_regularization
. tests/nn/regularizers_test.py::TestRegularizers::test_regularizer_applicator_respects_regex_matching
. tests/nn/util_test.py::TestNnUtil::test_add_positional_features
. tests/nn/util_test.py::TestNnUtil::test_add_sentence_boundary_token_ids_handles_2D_input
. tests/nn/util_test.py::TestNnUtil::test_add_sentence_boundary_token_ids_handles_3D_input
. tests/nn/util_test.py::TestNnUtil::test_batched_index_select
. tests/nn/util_test.py::TestNnUtil::test_bucket_values
. tests/nn/util_test.py::TestNnUtil::test_flatten_and_batch_shift_indices
. tests/nn/util_test.py::TestNnUtil::test_flattened_index_select
. tests/nn/util_test.py::TestNnUtil::test_get_sequence_lengths_converts_to_long_tensor_and_avoids_variable_overflow
. tests/nn/util_test.py::TestNnUtil::test_get_sequence_lengths_from_binary_mask
. tests/nn/util_test.py::TestNnUtil::test_get_text_field_mask_returns_a_correct_mask
. tests/nn/util_test.py::TestNnUtil::test_get_text_field_mask_returns_a_correct_mask_character_only_input
. tests/nn/util_test.py::TestNnUtil::test_get_text_field_mask_returns_a_correct_mask_list_field
. tests/nn/util_test.py::TestNnUtil::test_last_dim_softmax_does_softmax_on_last_dim
. tests/nn/util_test.py::TestNnUtil::test_last_dim_softmax_handles_mask_correctly
. tests/nn/util_test.py::TestNnUtil::test_logsumexp
. tests/nn/util_test.py::TestNnUtil::test_masked_log_softmax_masked
. tests/nn/util_test.py::TestNnUtil::test_masked_softmax_masked
. tests/nn/util_test.py::TestNnUtil::test_masked_softmax_no_mask
. tests/nn/util_test.py::TestNnUtil::test_remove_sentence_boundaries
. tests/nn/util_test.py::TestNnUtil::test_replace_masked_values_replaces_masked_values_with_finite_value
. tests/nn/util_test.py::TestNnUtil::test_sequence_cross_entropy_with_logits_averages_batch_correctly
. tests/nn/util_test.py::TestNnUtil::test_sequence_cross_entropy_with_logits_masks_loss_correctly
. tests/nn/util_test.py::TestNnUtil::test_sort_tensor_by_length
. tests/nn/util_test.py::TestNnUtil::test_sort_tensor_by_length_raises_on_non_variable_inputs
. tests/nn/util_test.py::TestNnUtil::test_viterbi_decode
. tests/nn/util_test.py::TestNnUtil::test_weighted_sum_handles_3d_attention_with_3d_matrix
. tests/nn/util_test.py::TestNnUtil::test_weighted_sum_handles_higher_order_input
. tests/nn/util_test.py::TestNnUtil::test_weighted_sum_handles_uneven_higher_order_input
. tests/nn/util_test.py::TestNnUtil::test_weighted_sum_works_on_simple_input
. tests/service/server_flask_test.py::TestFlask::test_caching
. tests/service/server_flask_test.py::TestFlask::test_disable_caching
. tests/service/server_flask_test.py::TestFlask::test_list_models
. tests/service/server_flask_test.py::TestFlask::test_machine_comprehension
. tests/service/server_flask_test.py::TestFlask::test_missing_static_dir
. tests/service/server_flask_test.py::TestFlask::test_permalinks_fail_gracefully_with_no_database
. tests/service/server_flask_test.py::TestFlask::test_permalinks_work
. tests/service/server_flask_test.py::TestFlask::test_semantic_role_labeling
. tests/service/server_flask_test.py::TestFlask::test_textual_entailment
. tests/service/server_flask_test.py::TestFlask::test_unknown_model
. tests/service/predictors/bidaf_test.py::TestBidafPredictor::test_batch_prediction
. tests/service/predictors/bidaf_test.py::TestBidafPredictor::test_uses_named_inputs
. tests/service/predictors/coref_test.py::TestCorefPredictor::test_uses_named_inputs
. tests/service/predictors/decomposable_attention_test.py::TestDecomposableAttentionPredictor::test_batch_prediction
. tests/service/predictors/decomposable_attention_test.py::TestDecomposableAttentionPredictor::test_uses_named_inputs
. tests/service/predictors/srl_test.py::TestSrlPredictor::test_uses_named_inputs
. tests/training/trainer_test.py::TestTrainer::test_should_stop_early_with_decreasing_metric
. tests/training/trainer_test.py::TestTrainer::test_should_stop_early_with_increasing_metric
. tests/training/trainer_test.py::TestTrainer::test_train_driver_raises_on_model_with_no_loss_key
F tests/training/trainer_test.py::TestTrainer::test_trainer_can_resume_training
 self = <tests.training.trainer_test.TestTrainer testMethod=test_trainer_can_resume_training>
 
     def test_trainer_can_resume_training(self):
         trainer = Trainer(self.model, self.optimizer,
                           self.iterator, self.dataset,
                           validation_dataset=self.dataset,
                           num_epochs=1, serialization_dir=self.TEST_DIR)
 >       trainer.train()
 
 tests/training/trainer_test.py:51: 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 allennlp/training/trainer.py:407: in train
     self._save_checkpoint(epoch, validation_metric_per_epoch, is_best=is_best_so_far)
 allennlp/training/trainer.py:457: in _save_checkpoint
     archive_model(self._serialization_dir, files_to_archive=self._files_to_archive)
 allennlp/models/archival.py:73: in archive_model
     archive.add(config_file, arcname=_CONFIG_NAME)
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/tarfile.py:1934: in add
     tarinfo = self.gettarinfo(name, arcname)
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
 
 self = <tarfile.TarFile object at 0x152a9e240>, name = '/tmp/allennlp_tests/model_params.json', arcname = 'config.json', fileobj = None
 
     def gettarinfo(self, name=None, arcname=None, fileobj=None):
         """Create a TarInfo object from the result of os.stat or equivalent
                on an existing file. The file is either named by `name', or
                specified as a file object `fileobj' with a file descriptor. If
                given, `arcname' specifies an alternative name for the file in the
                archive, otherwise, the name is taken from the 'name' attribute of
                'fileobj', or the 'name' argument. The name should be a text
                string.
             """
         self._check("awx")
     
         # When fileobj is given, replace name by
         # fileobj's real name.
         if fileobj is not None:
             name = fileobj.name
     
         # Building the name of the member in the archive.
         # Backward slashes are converted to forward slashes,
         # Absolute paths are turned to relative paths.
         if arcname is None:
             arcname = name
         drv, arcname = os.path.splitdrive(arcname)
         arcname = arcname.replace(os.sep, "/")
         arcname = arcname.lstrip("/")
     
         # Now, fill the TarInfo object with
         # information specific for the file.
         tarinfo = self.tarinfo()
         tarinfo.tarfile = self  # Not needed
     
         # Use os.stat or os.lstat, depending on platform
         # and if symlinks shall be resolved.
         if fileobj is None:
             if hasattr(os, "lstat") and not self.dereference:
 >               statres = os.lstat(name)
 E               FileNotFoundError: [Errno 2] No such file or directory: '/tmp/allennlp_tests/model_params.json'
 
 ../../../env/miniconda3/envs/scaffolding/lib/python3.6/tarfile.py:1803: FileNotFoundError
. tests/training/trainer_test.py::TestTrainer::test_trainer_can_run
. tests/training/metrics/boolean_accuracy_test.py::BooleanAccuracyTest::test_accuracy_computation
. tests/training/metrics/categorical_accuracy_test.py::CategoricalAccuracyTest::test_categorical_accuracy
. tests/training/metrics/categorical_accuracy_test.py::CategoricalAccuracyTest::test_top_k_categorical_accuracy
. tests/training/metrics/categorical_accuracy_test.py::CategoricalAccuracyTest::test_top_k_categorical_accuracy_accumulates_and_resets_correctly
. tests/training/metrics/categorical_accuracy_test.py::CategoricalAccuracyTest::test_top_k_categorical_accuracy_catches_exceptions
. tests/training/metrics/categorical_accuracy_test.py::CategoricalAccuracyTest::test_top_k_categorical_accuracy_respects_mask
. tests/training/metrics/categorical_accuracy_test.py::CategoricalAccuracyTest::test_top_k_categorical_accuracy_works_for_sequences
. tests/training/metrics/entropy_test.py::EntropyTest::test_entropy_for_uniform_distribution
. tests/training/metrics/entropy_test.py::EntropyTest::test_low_entropy_distribution
. tests/training/metrics/entropy_test.py::EntropyTest::test_masked_case
. tests/training/metrics/f1_measure_test.py::F1MeasureTest::test__f1_measure_catches_exceptions
. tests/training/metrics/f1_measure_test.py::F1MeasureTest::test_f1_measure
. tests/training/metrics/f1_measure_test.py::F1MeasureTest::test_f1_measure_accumulates_and_resets_correctly
. tests/training/metrics/f1_measure_test.py::F1MeasureTest::test_f1_measure_works_for_sequences
. tests/training/metrics/non_bio_span_based_f1_measure_test.py::NonBioSpanBasedF1Test::test_extract_spans
. tests/training/metrics/non_bio_span_based_f1_measure_test.py::NonBioSpanBasedF1Test::test_span_f1_can_build_from_params
. tests/training/metrics/non_bio_span_based_f1_measure_test.py::NonBioSpanBasedF1Test::test_span_metrics_are_computed_correctly_for_correct_segmentation
. tests/training/metrics/non_bio_span_based_f1_measure_test.py::NonBioSpanBasedF1Test::test_span_metrics_are_computed_correctly_for_incorrect_segmentation
. tests/training/metrics/span_based_f1_measure_test.py::SpanBasedF1Test::test_span_based_f1_extracts_correct_spans
. tests/training/metrics/span_based_f1_measure_test.py::SpanBasedF1Test::test_span_based_f1_ignores_specified_tags
. tests/training/metrics/span_based_f1_measure_test.py::SpanBasedF1Test::test_span_f1_can_build_from_params
. tests/training/metrics/span_based_f1_measure_test.py::SpanBasedF1Test::test_span_metrics_are_computed_correcly_with_prediction_map
. tests/training/metrics/span_based_f1_measure_test.py::SpanBasedF1Test::test_span_metrics_are_computed_correctly
